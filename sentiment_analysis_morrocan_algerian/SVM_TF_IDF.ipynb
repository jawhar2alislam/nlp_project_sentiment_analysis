{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx_CQweyUueD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', str(text))\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "def custom_tokenizer(text):\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    tokens = re.findall(r'\\w{2,}|\\:\\w+\\:', text)\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "G4benYQiUzzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "val_df = pd.read_csv('/content/validation.csv')\n"
      ],
      "metadata": {
        "id": "UkeFlEsKU1uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [train_df, test_df, val_df]:\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    df['clean_tweet'] = df['tweet'].apply(clean_tweet)\n"
      ],
      "metadata": {
        "id": "Kyv5HCvxU4E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_text = train_df['clean_tweet']\n",
        "y_train = train_df['label']\n",
        "X_test_text = test_df['clean_tweet']\n",
        "y_test = test_df['label']\n",
        "X_val_text = val_df['clean_tweet']\n",
        "y_val = val_df['label']\n"
      ],
      "metadata": {
        "id": "eCaSgeRpU66V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "weights_dict = dict(zip(np.unique(y_train), class_weights))\n"
      ],
      "metadata": {
        "id": "fuo76AnqU73X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(tokenizer=custom_tokenizer, lowercase=True, max_features=5000, stop_words='english')),\n",
        "    ('svd', TruncatedSVD(n_iter=7, random_state=42)),\n",
        "    ('svc', SVC(class_weight=weights_dict, kernel='rbf', random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'svd__n_components': [100, 200, 300],\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__gamma': ['scale', 0.01, 0.001]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
        "grid.fit(X_train_text, y_train)\n"
      ],
      "metadata": {
        "id": "xcEJqbm5U9fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "y_train_pred = best_model.predict(X_train_text)\n",
        "y_test_pred = best_model.predict(X_test_text)\n",
        "y_val_pred = best_model.predict(X_val_text)\n",
        "\n",
        "print(\"âœ… Meilleurs paramÃ¨tres :\", grid.best_params_)\n",
        "print(f\"âœ… Accuracy (Train) : {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"âœ… Accuracy (Test)  : {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"âœ… Accuracy (Val)   : {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "id": "iz-q4BLUU_un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['positive', 'neutral', 'negative']\n",
        "print(\"\\nðŸ“Š Rapport (Test) :\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=target_names))\n"
      ],
      "metadata": {
        "id": "FpnGFey2VECl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_test_pred, labels=[0, 1, 2])\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=target_names,\n",
        "            yticklabels=target_names)\n",
        "plt.title('Matrice de confusion - Test set')\n",
        "plt.xlabel('PrÃ©dit')\n",
        "plt.ylabel('RÃ©el')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yaC-DyLBVE-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_label = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
        "for idx in np.random.choice(len(test_df), 5, replace=False):\n",
        "    print(\"Tweet :\", test_df['tweet'].iloc[idx])\n",
        "    print(\"Vrai label :\", inv_label[y_test.iloc[idx]], \"| PrÃ©dit :\", inv_label[y_test_pred[idx]])\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "8BHudrIVVKEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sans emojis\n",
        "def clean_no_emoji(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', str(text))\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    return text.lower().strip()\n",
        "\n",
        "X_train_no_emoji = train_df['tweet'].apply(clean_no_emoji)\n",
        "X_test_no_emoji = test_df['tweet'].apply(clean_no_emoji)\n",
        "X_val_no_emoji = val_df['tweet'].apply(clean_no_emoji)\n",
        "\n",
        "# 2. Pipeline ablatif\n",
        "ablation_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(lowercase=True, max_features=5000, stop_words='english')),  # sans tokenizer personnalisÃ©\n",
        "    ('svd', TruncatedSVD(n_iter=7, random_state=42)),\n",
        "    ('svc', SVC(kernel='rbf', random_state=42))  # sans class_weight\n",
        "])\n",
        "\n",
        "ablation_pipeline.fit(X_train_no_emoji, y_train)\n",
        "y_pred_ablation = ablation_pipeline.predict(X_test_no_emoji)\n",
        "\n",
        "print(\"\\nðŸ”¬ Rapport dâ€™ablation (sans emoji + sans pondÃ©ration) :\")\n",
        "print(classification_report(y_test, y_pred_ablation, target_names=target_names))\n",
        "print(f\"Accuracy : {accuracy_score(y_test, y_pred_ablation):.4f}\")\n"
      ],
      "metadata": {
        "id": "hnBw7tRnVLIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}